# Weekly Progress Report – Ash

**Project:** IDQS Summer '25  
**Week of:** June 19th, 2025 (Week 7)

---

## ✅ Accomplishments

## 🔜 Next Steps

## Schema Awareness

- Prompt engineering for LLMs will be crucial for effective data retrieval, and with the database schema in place, we can optimize our queries and responses.

```
schema_context = """
You have access to the following table:
Table: orders
Columns: order_id (int), customer_name (text), total_amount (float), order_date (date)
"""
```

## LLM Integration

## Prompt Engineering

## Connect to Database

<!-- 🧠 Core Steps of a RAG System
Step	Description	Your Implementation So Far
1️⃣ User Input	Prompt/question from user	✅ HTML form → JS → Flask POST
2️⃣ Preprocessing	(Optional) Clean or interpret prompt	⬜︎ Can add later
3️⃣ Retrieve	Pull relevant context/data from DB or vector store	🟡 You’ll add this soon
4️⃣ Augment Prompt	Combine user prompt + retrieved info	⬜︎ Soon
5️⃣ Generate	Feed prompt into LLM to generate answer	🟡 Using a dummy/stub for now
6️⃣ Respond	Return LLM response to user	✅ Working now via /ask -->